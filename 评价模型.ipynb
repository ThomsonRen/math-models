{"cells":[{"source":"# 评价问题介绍","cell_type":"markdown","metadata":{"trusted":true,"collapsed":false,"tags":[],"slideshow":{"slide_type":"slide"},"id":"8478FBF13EA7419BA3A250ED42FE1112","scrolled":false,"mdEditEnable":false,"jupyter":{}}},{"metadata":{"id":"41E8AA5A96574DBC8F641EB3B3CBC389","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"我们常常会遇到如下的综合评价问题：**在若干个(同类)对象中，从多个维度对其进行评分，将这些评分综合后，给定一个最终排名。**"},{"metadata":{"id":"BC50ED5DF5D948C784CB75BF377D31F9","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"评价模型是数学建模比赛中最基础也是最常用的模型, 例如[2018年HiMCM A题](https://www.comap.com/highschool/contests/himcm/2018problems.html) 专门考察了评价模型。这里我们简单回顾下\r\n"},{"metadata":{"id":"C3551DA905724696852B23E77D93CBD7","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"> There are several Roller Coaster rating/ranking sites online that, while taking some objective measures into account, heavily rely on subjective input to determine the rating or ranking of a particular roller coaster (e.g., an \"excitement\"or \"experience\" score of an \"expert\" rider to measure \"thrill\").\r\n\r\n> In addressing this HiMCM problem, consider only roller coasters currently in operation. We have provided data for a subset of operating roller coasters whose height, speed, and/or drop are above the average of worldwide operating coasters. Therefore, we have not included family or kiddie coasters, nor have we included bobsled or mountain type coasters.\r\n\r\n> 1. Create an **objective quantitative algorithm** or set of algorithms to develop a descriptive roller coaster rating/ranking system based only on roller coaster numerical and descriptive specification data (e.g., speed, duration of ride, steel or wood, drop).\r\n\r\n> 2. Use your algorithm(s) to **develop your \"Top 10 Roller Coasters in the World\" list.** Compare and discuss the rating/ranking results and descriptions from your team's algorithm(s) with at least two other rating/ranking systems found online.\r\n\r\n> 3. Describe the concept and **design for a user-friendly app** that uses your algorithm(s) to help a potential roller coaster rider find a roller coaster that she or he would want to ride. NOTE: You DO NOT need to program and/or write code for the app. You are developing the concept and design for the app only.\r\n\r\n> 4. Write **a one-page non-technical News Release **describing your new algorithm, results, and app. \r\n"},{"metadata":{"id":"234CA31BC04645E0813F2BA4085CE3F9","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"                          Name                             Park   City/Region  \\\n0  10 Inversion Roller Coaster               Chimelong Paradise         Panyu   \n1                       Abismo  Parque de Atracciones de Madrid        Madrid   \n2              Adrenaline Peak              Oaks Amusement Park      Portland   \n3                    Afterburn                        Carowinds     Charlotte   \n4                   Alpengeist       Busch Gardens Williamsburg  Williamsburg   \n\n      City/State/Region Country/Region Geographic Region Construction  \\\n0  Guangzhou, Guangdong          China              Asia        Steel   \n1                Madrid          Spain            Europe        Steel   \n2                Oregon  United States     North America        Steel   \n3        North Carolina  United States     North America        Steel   \n4              Virginia  United States     North America        Steel   \n\n       Type      Status  Year/Date Opened Height (feet)   Speed (mph)  \\\n0  Sit Down   Operating              2006          98.4          45.0   \n1  Sit Down   Operating              2006         151.6          65.2   \n2  Sit Down  Operating               2018          72.0          45.0   \n3  Inverted   Operating              1999         113.0          62.0   \n4  Inverted   Operating              1997         195.0          67.0   \n\n   Length (feet) Inversions (YES or NO)  Number of Inversions Drop (feet)  \\\n0         2788.8                    YES                    10         NaN   \n1         1476.4                    YES                     2         NaN   \n2         1050.0                    YES                     3         NaN   \n3         2956.0                    YES                     6         NaN   \n4         3828.0                    YES                     6       170.0   \n\n  Duration (min:sec) G Force  Vertical Angle (degrees)  \n0               1:32     NaN                       NaN  \n1               1:00       4                       NaN  \n2                NaN     NaN                      97.0  \n3               2:47     NaN                       NaN  \n4               3:10     3.7                       NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Park</th>\n      <th>City/Region</th>\n      <th>City/State/Region</th>\n      <th>Country/Region</th>\n      <th>Geographic Region</th>\n      <th>Construction</th>\n      <th>Type</th>\n      <th>Status</th>\n      <th>Year/Date Opened</th>\n      <th>Height (feet)</th>\n      <th>Speed (mph)</th>\n      <th>Length (feet)</th>\n      <th>Inversions (YES or NO)</th>\n      <th>Number of Inversions</th>\n      <th>Drop (feet)</th>\n      <th>Duration (min:sec)</th>\n      <th>G Force</th>\n      <th>Vertical Angle (degrees)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10 Inversion Roller Coaster</td>\n      <td>Chimelong Paradise</td>\n      <td>Panyu</td>\n      <td>Guangzhou, Guangdong</td>\n      <td>China</td>\n      <td>Asia</td>\n      <td>Steel</td>\n      <td>Sit Down</td>\n      <td>Operating</td>\n      <td>2006</td>\n      <td>98.4</td>\n      <td>45.0</td>\n      <td>2788.8</td>\n      <td>YES</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>1:32</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Abismo</td>\n      <td>Parque de Atracciones de Madrid</td>\n      <td>Madrid</td>\n      <td>Madrid</td>\n      <td>Spain</td>\n      <td>Europe</td>\n      <td>Steel</td>\n      <td>Sit Down</td>\n      <td>Operating</td>\n      <td>2006</td>\n      <td>151.6</td>\n      <td>65.2</td>\n      <td>1476.4</td>\n      <td>YES</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>1:00</td>\n      <td>4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Adrenaline Peak</td>\n      <td>Oaks Amusement Park</td>\n      <td>Portland</td>\n      <td>Oregon</td>\n      <td>United States</td>\n      <td>North America</td>\n      <td>Steel</td>\n      <td>Sit Down</td>\n      <td>Operating</td>\n      <td>2018</td>\n      <td>72.0</td>\n      <td>45.0</td>\n      <td>1050.0</td>\n      <td>YES</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>97.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Afterburn</td>\n      <td>Carowinds</td>\n      <td>Charlotte</td>\n      <td>North Carolina</td>\n      <td>United States</td>\n      <td>North America</td>\n      <td>Steel</td>\n      <td>Inverted</td>\n      <td>Operating</td>\n      <td>1999</td>\n      <td>113.0</td>\n      <td>62.0</td>\n      <td>2956.0</td>\n      <td>YES</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>2:47</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Alpengeist</td>\n      <td>Busch Gardens Williamsburg</td>\n      <td>Williamsburg</td>\n      <td>Virginia</td>\n      <td>United States</td>\n      <td>North America</td>\n      <td>Steel</td>\n      <td>Inverted</td>\n      <td>Operating</td>\n      <td>1997</td>\n      <td>195.0</td>\n      <td>67.0</td>\n      <td>3828.0</td>\n      <td>YES</td>\n      <td>6</td>\n      <td>170.0</td>\n      <td>3:10</td>\n      <td>3.7</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"transient":{},"execution_count":1}],"source":"import pandas as pd\ndata = pd.read_csv(\"/home/kesci/input/Math_basic4405/COMAP_RollerCoasterData_2018.csv\")\ndata.head()","execution_count":1},{"metadata":{"id":"59E0309E704E449A84B6FDDACCB11296","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"如何构成一个综合评价问题呢？通常有如下五个角度\n- **评价对象：**评价对象就是综合评价问题中所研究的对象，或称为系统。通常情况下，在一个问题中评价对象是属于同一类的，且个数要大于1，不妨假设一个综合评价问题中有$n$个评价对象，分别记为\n$$\nS_{1}, S_{2}, \\cdots, S_{n}(n>1)\n$$\n- **评价指标:**评价指标是反映评价对象的运行（或发展）状况的基本要素。通常的问题都是有多项指标构成，每一项指标都是从不同的侧面刻画系统所具有某种特征大小的一个度量。一个综合评价问题的评价指标一般可用一个向量$x$表示，称为评价指标问题，其中每一个分量就是从一个侧面反映系统的状态，即称为综合评价的指标体系。不失一般性，设系统有$m$个评价指标，分别记为\n$$\nx_{1}, x_{2}, \\cdots, x_{m}(m>1)\n$$\n\n- **权重系数:**每一个综合评价问题都有相应的评价目的，针对某种评价目的，各评价指标之间的相对重要性是不同的，评价指标之间的这种相对重要性的大小，可用权重系数来刻画。如果用$w_{j}(j=1,2, \\cdots, m)$来表示评价指标$x_j$的权重系数，一般应满足\n$$\nw_{j} \\geq 0, j=1,2, \\cdots, m  \\quad  并且  \\quad  \\sum_{j=1}^{m} w_{j}=1\n$$\n当各评价对象和评价指标值都确定以后，综合评价结果就依赖于权重系数的取值了，即权重系数确定的合理与否，直接关系到综合评价结果的可信度，甚至影响到最后决策的正确性。因此，权重系数的确定要特别谨慎，应按一定的方法和原则来确定。\n- **综合模型**\n对于多指标（或多因素）的综合评价问题，就是要通过建立一定的数学模型将多个评价指标值综合成为一个整体的综合评价值，作为综合评价的依据，从而得到相应的评价结果。\n\n- **评价者**\n评价者是直接参与评价的人，可以是一个人，也可以是一个团体。对于评价目的选择、评价指标体系确定、权重系数的确定和评价模型的建立都与评价者有关。因此，评价者在评价过程中的作用是不可小视的。\n\n\n\n"},{"metadata":{"id":"24517C7CBD624E21B47BDC06B82FC6B9","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"目前国内外综合评价方法有数十种之多，其中主要使用的评价方法有\n - 主成分分析法、\n - 因子分析\n - **TOPSIS**\n - 秩和比法\n - 灰色关联法\n - **熵权法**\n - **层次分析法**\n - 模糊评价法\n - 物元分析法\n - 聚类分析法\n - 价值工程法\n - 神经网络法等\n\n本次课程，我们重点展开讲其中的**TOPSIS、熵权法和层次分析法**。"},{"metadata":{"id":"ACE84F13C16C4779A409CA53BED19880","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"# 数据预处理方法"},{"metadata":{"id":"33CF15E4A13C4BB4A36E563BD911FC31","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"一般情况下，在综合评价指标中，有的指标比较重要，有的影响微乎其微，另外各指标值可能属于不同类型、不同单位或不同数量级，从而使得各指标之间存在着不可公度性，给综合评价带来了诸多不便。为了尽可能地反映实际情况，消除由于各项指标间的这些差别带来的影响，避免出现不合理的评价结果，就需要对评价指标进行一定的预处理，包括\n\n- **指标的筛选**\n- **指标的一致化处理**\n- **无量纲化处理**\n\n下面分别介绍。"},{"metadata":{"id":"D87331E1D43940508293B385D33A5C90","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"## 评价指标的筛选方法\n\n要根据综合评价的目的，针对具体的评价对象、评价内容收集有关指标信息，采用适当的筛选方法对指标进行筛选，合理地选取主要指标，剔除次要指标，以简化评价指标体系。常用的评价指标筛选方法主要有专家调研法、**最小均方差法、极大极小离差法**等。我们重点来看后两种方法。\n"},{"metadata":{"id":"42BA1EAD22B042708410745BA2879078","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"### 最小均方差法\n\n对于$n$个评价对象$S_{1}, S_{2}, \\cdots, S_{n}$，每个评价对象有$m$个指标，其观测值分别为\n\n$$\na_{i j}(i=1,2, \\cdots, n ; j=1,2, \\cdots, m)\n$$\n\n如果$n$个评价对象关于某项指标的观测值都差不多，那么不管这个评价指标重要与否，对于这$n$个评价对象的评价结果所起的作用将是很小的。因此，在评价过程中就可以删除这样的评价指标。\n\n最小均方差法的筛选过程如下：\n\n1. 首先求出第$j$项指标的平均值和均方差\n$$\n\\mu_{j}=\\frac{1}{n} \\sum_{i=1}^{n} a_{i j}, s_{j}=\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}\\left(a_{i j}-\\mu_{j}\\right)^{2}}, \\quad j=1,2, \\cdots, m\n$$\n2. 求出最小均方差\n$$\n\\boldsymbol{S}_{j_{0}}=\\min _{1 \\leq j \\leq m}\\left\\{\\boldsymbol{s}_{j}\\right\\}\n$$\n3. 如果最小均方差$S_{j_{0}} \\approx 0$，则可删除与$S_{j_{0}}$对应的指标 。考察完所有指标，即可得到最终的评价指标体系。\n\n> 注意：最小均方差法只考虑了指标的差异程度，容易将重要的指标删除。\n"},{"metadata":{"id":"138906245A6A41D6901811AD53E9BE1D","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"### 极大极小离差法"},{"metadata":{"id":"491D9CE19BE04CC5A77CAB1445A2FF66","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"对于$n$个评价对象$S_{1}, S_{2}, \\cdots, S_{n}$，每个评价对象有$m$个指标，其观测值分别为\n$$\na_{i j}(i=1,2, \\cdots, n ; j=1,2, \\cdots, m)\n$$\n\n极大极小离差法的筛选过程如下：\n1. 求出第$j$项指标的最大离差\n$$\nd_{j}=\\max _{1 \\leq i,k \\leq n}\\left\\{\\left|a_{i j}-a_{k j}\\right|\\right\\}, j=1,2, \\cdots, m\n$$\n2. 求出最小离差\n$$\nd_{j_{0}}=\\min _{1 \\leq j \\leq n}\\left\\{d_{j}\\right\\}\n$$\n3. 如果最小离差$d_{j_{0}} \\approx 0$，则可删除与$d_{j_{0}}$对应的指标$x_{j_{0}}$，考察完所有指标，即可得到最终的评价指标体系。\n\n常用的评价指标筛选方法还有条件广义方差极小法、极大不相关法等，详细介绍可参阅相关资料。\n"},{"metadata":{"id":"8C7F97C63A244B9186E341D99332C46A","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"## 指标的一致化处理\n\n所谓一致化处理就是将评价指标的类型进行统一。一般来说，在评价指标体系中，可能会同时存在极大型指标、极小型指标、居中型指标和区间型指标，它们都具有不同的特点。若指标体系中存在不同类型的指标，必须在综合评价之前将评价指标的类型做一致化处理。**例如，将各类指标都转化为极大型指标，或极小型指标。一般的做法是将非极大型指标转化为极大型指标。**但是，在不同的指标权重确定方法和评价模型中，指标一致化处理也有差异。"},{"metadata":{"id":"9666E50DDCB64883BBC824C3B3B624F4","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"### 极小型指标化为极大型指标\n\n对极小型指标$x_j$，将其转化为极大型指标时，只需对指标$x_j$取倒数：\n$$\nx_{j}^{\\prime}=\\frac{1}{x_{j}}\n$$\n\n或做平移变换：\n\n$$\nx_{j}^{\\prime}=M_{j}-x_{j}\n$$\n\n其中,$M_{j}=\\max _{1 \\leq i \\leq n}\\left\\{a_{i j}\\right\\}$,即$n$个评价对象第$j$项指标值$a_{ij}$最大者。"},{"metadata":{"id":"9877ADF4BCF44D1D801366411DBFAC22","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"### 居中型指标化为极大型指标\n\n对居中型指标$x_j$,令$M_{j}=\\max _{1 \\leq i \\leq n}\\left\\{a_{i j}\\right\\}, \\quad m_{j}=\\min _{1 \\leq i \\leq n}\\left\\{a_{i j}\\right\\}$,取\n$$\nx_{j}^{\\prime}=\\left\\{\\begin{array}{ll}\n{\\frac{2\\left(x_{j}-m_{j}\\right)}{M_{j}-m_{j}},} & {m_{j} \\leq x_{j} \\leq \\frac{M_{j}+m_{j}}{2}} \\\\\n{\\frac{2\\left(M_{j}-x_{j}\\right)}{M_{j}-m_{j}},} & {\\frac{M_{j}+m_{j}}{2} \\leq x_{j} \\leq M_{j}}\n\\end{array}\\right.\n$$\n\n就可以将$x_j$转化为极大型指标。"},{"metadata":{"id":"E30ABB18FC2146C1AAF2868CE9BEF0E9","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"### 区间型指标化为极大型指标\n\n对区间型指标$x_j$， $x_j$是取值介于区间$\\left[b_{j}^{(1)}, b_{j}^{(2)}\\right]$,内时为最好，指标值离该区间越远就越差。令\n$$\nM_{j}=\\max _{1 \\leq i \\leq n}\\left\\{a_{i j}\\right\\}, \\quad m_{j}=\\min _{\\| \\leq i \\leq n}\\left\\{a_{i j}\\right\\}, \\quad c_{j}=\\max \\left\\{b_{j}^{(1)}-m_{j}, M_{j}-b_{j}^{(2)}\\right\\}\n$$\n\n就可以将区间型指标$x_j$转化为极大型指标。\n$$\nx_{j}'=\\left\\{\\begin{array}{ll}\n{1-\\dfrac{b_{j}^{(1)}-x_{j}}{c_{j}},} & {x_{j}<b_{j}^{(1)}} \\\\\n{1,} & {b_{j}^{(1)} \\leq x_{j} \\leq b_{j}^{(2)}} \\\\\n{1-\\dfrac{x_{j}-b_{j}^{(2)}}{c_{j}},} & {x_{j}>b_{j}^{(2)}}\n\\end{array}\\right.\n$$\n\n\n"},{"metadata":{"id":"306F6FB12C8F4767A5AE374EB2DB7E69","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"## 指标的无量纲化处理"},{"metadata":{"id":"ABD711F3126C453DAEC7060738A2D77E","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"**所谓无量纲化，也称为指标的规范化，是通过数学变换来消除原始指标的单位及其数值数量级影响的过程。**因此，就有指标的实际值和评价值之分。一般地，将指标无量纲化处理以后的值称为指标评价值。无量纲化过程就是将指标实际值转化为指标评价值的过程。\n\n对于$n$个评价对象$S_{1}, S_{2}, \\cdots, S_{n}$，每个评价对象有$m$个指标，其观测值分别为\n$$\na_{i j}(i=1,2, \\cdots, n ; j=1,2, \\cdots, m)\n$$\n\n### 标准样本变换法\n\n令\n$$\na_{i j}^{*}=\\frac{a_{i j}-\\mu_{j}}{s_{j}}(1 \\leq i \\leq n, 1 \\leq j \\leq m)\n$$\n\n其中样本均值$\\mu_{j}=\\frac{1}{n} \\sum_{i=1}^{n} a_{i j}$,样本均方差$s_{j}=\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}\\left(a_{i j}-\\mu_{j}\\right)^{2}}$,称为标准观测值。"},{"metadata":{"id":"669FE474FC2A40048306B83E43EC536F","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"### 比例变换法\n\n对于极大型指标，令\n\n$$\na_{i j}^{*}=\\frac{a_{i j}}{\\max _{1 \\leq i \\leq n} a_{i j}}\\left(\\max _{1 \\leq i \\leq n} a_{i j} \\neq 0,1 \\leq i \\leq n, 1 \\leq j \\leq m\\right)\n$$\n\n对极小型指标，令\n$$\na_{i j}^{*}=\\frac{\\min a_{i j}}{a_{i j}}(1 \\leq i \\leq n, 1 \\leq j \\leq m)\n$$\n\n或\n$$\na_{i j}^{*}=1-\\frac{a_{i j}}{\\max _{1 \\leq i \\leq n} a_{i j}}\\left(\\max _{1 \\leq i \\leq n} a_{i j} \\neq 0,1 \\leq i \\leq n, 1 \\leq j \\leq m\\right)\n$$\n\n该方法的优点是这些变换前后的属性值成比例。但对任一指标来说，变换后的$a_{i j}^{*} = 1$和$a_{i j}^{*}= 0$不一定同时出现。"},{"metadata":{"id":"6745CF6D810A4E9F8C8D110C2108DA8D","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"### 向量归一化法\n\n对于极大型指标，令\n$$\na_{i j}^{*}=\\frac{a_{i j}}{\\sqrt{\\sum_{i=1}^{n} a_{i j}^{2}}}(i=1,2, \\cdots, n, 1 \\leq j \\leq m)\n$$\n\n\n对于极小型指标，令\n\n$$\na_{i j}^{*}=1-\\frac{a_{i j}}{\\sqrt{\\sum_{i=1}^{n} a_{i j}^{2}}}(i=1,2, \\cdots, n, 1 \\leq j \\leq m)\n$$\n\n### 极差变换法\n对于极大型指标\n$$\na_{i j}^{*}=\\frac{a_{i j}-\\min _{1 \\leq i \\leq n} a_{i j}}{\\max _{1 \\leq i \\leq n} a_{i j}-\\min _{1 \\leq i \\leq n} a_{i j}}(1 \\leq i \\leq n, 1 \\leq j \\leq m)\n$$\n\n对于极小型直指标\n\n$$\na_{i j}^{*}=\\frac{\\max _{1 \\leq i \\leq n} a_{i j}-a_{i j}}{\\max _{1 \\leq i \\leq n} a_{i j}-\\min _{1 \\leq i \\leq n} a_{i j}}(1 \\leq i \\leq n, 1 \\leq j \\leq m)\n$$\n\n\n其特点为经过极差变换后，均有$0 \\leq a_{i j}^{*} \\leq 1$，且最优指标值$a_{i j}^{*}=1$，最劣指标值$a_{i j}^{*}=0$。该方法的缺点是变换前后的各指标值不成比例。\n\n\n### 功效系数法\n\n令，\n\n$$\na_{i j}^{*}=c+\\frac{a_{i j}-\\min _{1 \\leq i \\leq n} a_{i j}}{\\max _{1 \\leq i \\leq n} a_{i j}-\\min _{1 \\leq i \\leq n} a_{i j}} \\times d(1 \\leq i \\leq n, 1 \\leq j \\leq m)\n$$\n\n其$c,d$均为确定的常数，$c$表示“平移量”，表示指标实际基础值， $d$表示“旋转量”，即表示“放大”或“缩小”倍数"},{"metadata":{"id":"942B6E5BAAA44EDBB0C2B3D83708130A","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"## 定性指标的定量化\n\n在综合评价工作中，有些评价指标是定性指标，即只给出定性的描述，例如，质量很好、性能一般、可靠性高等。对于这些指标，在进行综合评价时，必须先通过适当的方式进行赋值，使其量化。一般来说，对于指标最优值可赋值1，对于指标最劣值可赋值0。对极大型定性指标常按以下方式赋值。\n\n\n对于极大型定性指标而言，如果指标能够分为很低、低、一般、高和很高五个等级，则可以分别取量化值为0，0.1，0.3，0.5，0.7，1，对应关系如下表所示。介于两个等级之间的可以取两个分值之间的适当数值作为量化值。极小型指标同理。\n\n| 等级   | 很低 | 低  | 一般 | 高  | 很高 |\n|--------|------|-----|------|-----|------|\n| 量化值 | 0    | 0.3 | 0.5  | 0.7 | 0.9  |\n"},{"metadata":{"id":"E52755BE77324EFDB83C4A31E444BC83","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"# 常用综合模型介绍及案例分析\n"},{"metadata":{"id":"7BC6D3C962B142618039F9BB9E3CD003","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"下面我们通过几个例子来学习三种常用的评价模型。"},{"metadata":{"id":"6C63D4B497784E8987CE6EFD53D26D35","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"## TOPSIS方法\n\nC.L.Hwang 和 K.Yoon 于1981年首次提出 TOPSIS (全称：Technique for Order Preference by Similarity to an Ideal Solution)。\n\nTOPSIS 法是一种常用的组内综合评价方法，能充分利用原始数据的信息，其结果能精确地反映各评价方案之间的差距。基本过程为基于归一化后的原始数据矩阵，采用余弦法找出有限方案中的**最优方案和最劣方案**，然后分别计算各评价对象与最优方案和最劣方案间的距离，获得各评价对象与最优方案的相对接近程度，以此作为评价优劣的依据。该方法对数据分布及样本含量没有严格限制，数据计算简单易行。"},{"metadata":{"id":"9FE701D789E04FF98A64E8C3156EDE47","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"为了客观地评价我国研究生教育的实际状况和各研究生院的教学质量，国务院学位委员会办公室组织过一次研究生院的评估。为了取得经验，先选5所研究生院，收集有关数据资料进行了试评估，下表是所给出的部分数据：\n\n\n![Image Name](https://cdn.kesci.com/upload/image/q36cu5oq77.png?imageView2/0/w/960/h/960)\n"},{"metadata":{"id":"3A31289AD661495B9182B3D455B5D45B","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"TOPSIS 法使用距离尺度来度量样本差距，使用距离尺度就需要对指标属性进行同向化处理（若一个维度的数据越大越好，另一个维度的数据越小越好，会造成尺度混乱）。通常采用成本型指标向效益型指标转化（即数值越大评价越高，事实上几乎所有的评价方法都需要进行转化）"},{"metadata":{"id":"04339AC65C93403882509EDE239F3CA5","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"通过分析，我们知道：\n\n- 人均专著，越多越好（极大型指标）\n- 科研经费，越多越好（极大型指标）\n- 逾期毕业率，越小越好（极小型指标）\n- 生师比，过大过小都不好（区间型指标）\n\n设研究生院的生师比最佳区间为$[5,6]$ ，$a^* = 2$ ，$b^* = 12$ 。"},{"metadata":{"id":"54B01FDFF89E4BD281C3057FE3FA08FB","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"因此，我们把两个极大型指标保持不变，对极小型指标采用取倒数操作，对区间型指标使用指标一致化处理方法。处理结果见下图。"},{"metadata":{"id":"5453C5A9503C4E6D8D7FA5988929AA47","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"\n![Image Name](https://cdn.kesci.com/upload/image/q36dpsx5kl.png?imageView2/0/w/640/h/640)\n"},{"metadata":{"id":"F19D1268E9B6406C8E87C799B6FA7EDB","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"接下来，我们进行无量纲处理，以 \"人均专著\" 属性为例，我们使用向量归一化方法：\n$$\n\\begin{aligned}\n&0.1 / \\sqrt{0.1^{2}+0.2^{2}+0.4^{2}+0.9^{2}+1.2^{2}}=0.0637576713063384\\\\\n&0.2 / \\sqrt{0.1^{2}+0.2^{2}+0.4^{2}+0.9^{2}+1.2^{2}}=0.12751534261266767\\\\\n&0.4 / \\sqrt{0.1^{2}+0.2^{2}+0.4^{2}+0.9^{2}+1.2^{2}}=0.2550306852253334\\\\\n&\\begin{array}{l}\n{0.9 / \\sqrt{0.1^{2}+0.2^{2}+0.4^{2}+0.9^{2}+1.2^{2}}=0.5738190417570045} \\\\\n{1.2 / \\sqrt{0.1^{2}+0.2^{2}+0.4^{2}+0.9^{2}+1.2^{2}}=0.7650920556760059}\n\\end{array}\n\\end{aligned}\n$$"},{"metadata":{"id":"2AE3ECF7344E47508C1C330E4F54906C","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"使用同样的向量归一化方法，我们可以对其他三个指标也进行无量纲化处理，得到如下表所示的结果\n\n\n![Image Name](https://cdn.kesci.com/upload/image/q37a7zebvn.png?imageView2/0/w/640/h/640)\n"},{"metadata":{"id":"7DCFC168B7F94FAD972A815649AE6975","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"接着，我们选出其中的最优方案和最劣方案。\n\n![Image Name](https://cdn.kesci.com/upload/image/q37a9tyx43.png?imageView2/0/w/640/h/640)\n"},{"metadata":{"id":"68A912042FCF42999CA931326EADC3B4","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"然后，我们开始计算每一个学校，与最优方案以及最劣方案之间的距离\n$$\n\\begin{array}{l}\n{D_{i}^{+}=\\sqrt{\\sum_{j=1}^{m} w_{j}\\left(Z_{j}^{+}-z_{i j}\\right)^{2}}} \\\\\n{D_{i}^{-}=\\sqrt{\\sum_{j=1}^{m} w_{j}\\left(Z_{j}^{-}-z_{i j}\\right)^{2}}}\n\\end{array}\n$$\n\n然后使用如下的评价函数将其综合起来\n$$\nC_{i}=\\frac{D_{i}^{-}}{D_{i}^{+}+D_{i}^{-}}\n$$\n"},{"metadata":{"id":"62892C8559F2411DBD8B2FC10CC193FC","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"最终评价结果如下\n\n\n![Image Name](https://cdn.kesci.com/upload/image/q37aduhn3h.png?imageView2/0/w/960/h/960)\n"},{"metadata":{"id":"C041301C6278483E8769AEFE296BF364","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"\n"},{"metadata":{"id":"413BC272112D4C72ABEB61AF13425A9F","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{}},"cell_type":"code","outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:32: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n","name":"stderr"},{"output_type":"display_data","metadata":{},"data":{"text/plain":"<Figure size 432x432 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/rt_upload/413BC272112D4C72ABEB61AF13425A9F/q3l6ybbw9r.png\">"},"transient":{}}],"source":"# 导入第三方模块\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 中文和负号的正常显示\nplt.rcParams['font.sans-serif'] = 'Microsoft YaHei'\nplt.rcParams['axes.unicode_minus'] = False\n\n# 使用ggplot的绘图风格\nplt.style.use('ggplot')\n\n# 构造数据\n\nA = [0.063758,0.597022,0.344901,0.275343]\nB = [0.127, 0.597,0.413,0.231]\nC = [0.255,0.497,0.482,0.193]\nD = [0.573,0.199,0.689,0.562]\nE = [0.765,0,0.027,0.718]\n\nfeature = ['人均专著','生师比','科研经费','逾期毕业率']\n\nN = len(A)\n# 设置雷达图的角度，用于平分切开一个圆面\n\n# 为了使雷达图一圈封闭起来，需要下面的步骤\n\n\ndef plot_radar(values,fig):\n    angles=np.linspace(0, 2*np.pi, N, endpoint=False)\n    values=np.concatenate((values,[values[0]]))\n    angles=np.concatenate((angles,[angles[0]]))\n    ax = fig.add_subplot(111, polar=True)\n    # 绘制折线图\n    ax.plot(angles, values, 'o-', linewidth=2)\n    # 填充颜色\n    ax.fill(angles, values, alpha=0.25)\n    ax.set_thetagrids(angles * 180/np.pi, feature)\n    return ax\n\n# 绘图\nfig=plt.figure(figsize = (6,6))\nfor x in [A,B,C,D,E]: \n    ax = plot_radar(x,fig)\n\n\n\n# 添加每个特征的标签\n\n# 设置雷达图的范围\nax.set_ylim(0,1)\n# 添加标题\n\n# 添加网格线\nax.grid(True)\n# 设置图例\nplt.legend([\"A\",\"B\",\"C\",\"D\",\"E\"],loc = 'upper left')\n# 显示图形\nplt.show()","execution_count":4},{"metadata":{"id":"483908AB37324BE9AC0BD4FEDBDC0424","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"## 层次分析法\n\nAHP (Analytic Hierarchy Process)层次分析法是美国运筹学家Saaty教授于二十世纪80年代提出的一种实用的多方案或多目标的决策方法。其主要特征是，它合理地将定性与定量的决策结合起来，按照思维、心理的规律把决策过程层次化、数量化。 该方法自1982年被介绍到我国以来，以其定性与定量相结合地处理各种决策因素的特点，以及其系统灵活简洁的优点，迅速地在我国社会经济各个领域内，如能源系统分析、城市规划、经济管理、科研评价等，得到了广泛的重视和应用。\n\n层次分析法的基本思路：先分解后综合首先将所要分析的问题层次化，根据问题的性质和要达到的总目标，将问题分解成不同的组成因素，按照因素间的相互关系及隶属关系，将因素按不同层次聚集组合，形成一个多层分析结构模型，最终归结为最低层（方案、措施、指标等）相对于最高层（总目标）相对重要程度的权值或相对优劣次序的问题。 运用层次分析法建模，大体上可按下面四个步骤进行： \n\n- 建立递阶层次结构模型； \n- 构造出各层次中的所有判断矩阵； \n- 层次单排序及一致性检验； \n- 层次总排序及一致性检验。"},{"metadata":{"id":"B2E2B3FDC6404E0B8A1A4AD6E9004D79","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"人们在日常生活中经常会碰到多目标决策问题，例如假期某人想要出去旅游，现有三个目的地（方案）：风光绮丽的杭州（P1）、迷人的北戴河（P2）和山水甲天下的桂林（P3）。假如选择的标准和依据（行动方案准则）有5个：景色，费用，饮食，居住和旅途。则常规思维的方式如下：\n\n\n![Image Name](https://cdn.kesci.com/upload/image/q37ay9fgbp.png?imageView2/0/w/960/h/960)\n\n"},{"metadata":{"id":"EF93C66E657041D087A8656204483561","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"通过相互比较确定各准则对于目标的权重，即构造判断矩阵。在层次分析法中，为使矩阵中的各要素的重要性能够进行定量显示，引进了矩阵判断标度（1～9标度法） :\n\n\n![Image Name](https://cdn.kesci.com/upload/image/q37azh9ui8.png?imageView2/0/w/960/h/960)\n"},{"metadata":{"id":"B9AB0BE5A77F416B8067FBCCF8F5F8F2","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"构造判断矩阵"},{"metadata":{"id":"522775E32E864457ACC1DB9F66C07DF3","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"\n![Image Name](https://cdn.kesci.com/upload/image/q37b0ivv9d.png?imageView2/0/w/960/h/960)\n"},{"metadata":{"id":"224DC946B89949DF8040D3491473566B","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"### 层次单排序和总排序"},{"metadata":{"id":"B9A3C85283E943F485808C2B29302763","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"所谓层次单排序是指，对于上层某因素而言，本层次因素重要性的排序。\n具体计算方法为：对于判断矩阵$B$，计算满足\n$$\nBW=\\lambda_{max} W\n$$\n的特征根与特征向量。\n\n式中，$\\lambda_{max}$ 为矩阵$B$的最大特征跟根，$W$为对应于$\\lambda_{max}$的特征向量，$W$的分量$w_i$即为相应元素单排序的权值。"},{"metadata":{"id":"64E2A731671C41E1801B64DA43D2C4EB","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{}},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"[[1, 2, 5], [0.5, 1, 2], [0.2, 0.5, 1]]"},"transient":{},"execution_count":30}],"source":"A = [[1,2,5],[1/2,1,2],[1/5,1/2,1]]\nA","execution_count":30},{"metadata":{"id":"951D5B72403641A5B2A8895C107F5791","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{}},"cell_type":"code","outputs":[{"output_type":"stream","text":"[ 3.00553511e+00+0.j         -2.76755587e-03+0.12895082j\n -2.76755587e-03-0.12895082j]\n","name":"stdout"}],"source":"# 调用 np.linalg.eig方法计算矩阵的特征值和特征向量，其中lamb是特征值，v是特征向量\nlamb,v = np.linalg.eig(A)      \nprint(lamb)","execution_count":31},{"metadata":{"id":"DC9370AB8F214F498D0C806B3C9C4F32","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{}},"cell_type":"code","outputs":[{"output_type":"stream","text":"[[-0.89021421+0.j         -0.89021421+0.j         -0.89021421-0.j        ]\n [-0.41320083+0.j          0.20660042+0.35784242j  0.20660042-0.35784242j]\n [-0.19179084+0.j          0.09589542-0.16609574j  0.09589542+0.16609574j]]\n","name":"stdout"}],"source":"print(v)","execution_count":17},{"metadata":{"id":"B0488A42B9FE4386A660CA1F49A095F2","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{}},"cell_type":"code","outputs":[],"source":"lambda_max = max(abs(lamb))                    # 提取最大的特征值\nloc = np.where(lamb == lambda_max)             # 获取最大特征值的索引","execution_count":32},{"metadata":{"id":"6EE6BF5FAD10488E8F1D2F978B8AA946","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{}},"cell_type":"code","outputs":[{"output_type":"execute_result","metadata":{},"data":{"text/plain":"array([0.89021421, 0.41320083, 0.19179084])"},"transient":{},"execution_count":33}],"source":"weight = abs(v[0:len(A),loc[0][0]])            # 获取最大特征值对应的特征向量\nweight","execution_count":33},{"metadata":{"id":"74723C7BE6444F1F87FDB83A1236A775","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"\n![Image Name](https://cdn.kesci.com/upload/image/q37b2ynn0.png?imageView2/0/w/960/h/960)\n"},{"metadata":{"id":"2531C143D0964F02804E8F3A2AEC7628","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"$$\nW=W^{(3)} W^{(2)}=\\left(\\begin{array}{ccccc}\n{0.595} & {0.082} & {0.429} & {0.633} & {0.166} \\\\\n{0.277} & {0.236} & {0.429} & {0.193} & {0.166} \\\\\n{0.129} & {0.682} & {0.142} & {0.175} & {0.668}\n\\end{array}\\right)\\left(\\begin{array}{c}\n{0.263} \\\\\n{0.475} \\\\\n{0.055} \\\\\n{0.099} \\\\\n{0.110}\n\\end{array}\\right)=\\left(\\begin{array}{c}\n{0.300} \\\\\n{0.246} \\\\\n{0.456}\n\\end{array}\\right)\n$$"},{"metadata":{"id":"8F4796E9A3FB490482BAD2565F24C066","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"决策结果是首选旅游地为$P_3$ ,其次为$P_1$，再次$P_2$\n\n\n一般地，若层次结构由$k$个层次（目标层算第一层），则方案的优先程度的排序向量为:\n\n$$\nW=W^{(k)} W^{(k-1)} \\dots W^{(2)}\n$$\n\n"},{"metadata":{"id":"6A8F7F73101248C6AFBECC332CCDF0C6","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"### 判断一致性"},{"metadata":{"id":"CBFDF5CA17104F848490ACA973898058","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"判断矩阵通常是不一致的，但是为了能用它的对应于特征根的特征向量作为被比较因素的权向量，其不一致程度应在容许的范围内.如何确定这个范围？ \n\n一致性指标：\n\n$$\nC I=\\frac{\\lambda-n}{n-1}\n$$\n\n$$\nC R=\\frac{C I}{R I}\n$$\n\n\n![Image Name](https://cdn.kesci.com/upload/image/q37bi9mx9r.png?imageView2/0/w/960/h/960)\n"},{"metadata":{"id":"02867057725941B2969540A7F2538239","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"当$CR<0.1$时，认为层次排序是具有满意的一致性的，我们可以接受该分析结果。"},{"metadata":{"id":"9E552255CA724B178B51658A06E7BF62","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{}},"cell_type":"code","outputs":[{"output_type":"stream","text":"最大特征值 lambda_max= 3.075599563855794\n最大特征值对应的特征向量 w= [0.90191687 0.3919986  0.18133684]\nCI= 0.037799781927897014\nRI= 0.58\nCR= 0.065172037806719\n","name":"stdout"}],"source":"A = [[1,2,6],[1/2,1,2],[1/5,1/2,1]]\n# 调用 np.linalg.eig方法计算矩阵的特征值和特征向量，其中lamb是特征值，v是特征向量\nlamb,v = np.linalg.eig(A)      \nlambda_max = max(abs(lamb))                    # 提取最大的特征值\nloc = np.where(lamb == lambda_max)             # 获取最大特征值的索引\nweight = abs(v[0:len(A),loc[0][0]])            # 获取最大特征值对应的特征向量\nRI_list = [0 ,0 ,0.58,0.9,1.12,1.24,1.32,1.41,1.45]   \nRI = RI_list[len(A)-1]                        # 计算RI\nCI = (lambda_max - len(A))/(len(A)-1)         # 计算CI\nCR = CI / RI                                   # 计算CR\nprint('最大特征值 lambda_max=',lambda_max)\nprint('最大特征值对应的特征向量 w=',weight)\nprint('CI=',CI)\nprint('RI=',RI)\nprint('CR=',CR)","execution_count":36},{"metadata":{"id":"01C6DEF4826A4A67A8CE1C71BF1835D8","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"\n### 案例：企业的资金使用\n\n\n![Image Name](https://cdn.kesci.com/upload/image/q37bozvxls.png?imageView2/0/w/960/h/960)\n"},{"metadata":{"id":"3E0308B43B3542D28CD12D6C9EDF87E8","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"构造判断矩阵\n$$\nA=\\left(\\begin{array}{ccc}{1} & {1 / 5} & {1 / 3} \\\\ {5} & {1} & {3} \\\\ {3} & {1 / 3} & {1}\\end{array}\\right)\n$$\n\n$$\nB_{1}=\\left(\\begin{array}{ccccc}{1} & {2} & {3} & {4} & {7} \\\\ {1 / 3} & {1} & {3} & {2} & {5} \\\\ {1 / 5} & {1 / 3} & {1} & {1 / 2} & {1} \\\\ {1 / 4} & {1 / 2} & {2} & {1} & {3} \\\\ {1 / 7} & {1 / 5} & {1 / 2} & {1 / 3} & {1}\\end{array}\\right) \\quad B_{2}=\\left(\\begin{array}{cccc}{1} & {1 / 7} & {1 / 3} & {1 / 5} \\\\ {7} & {1} & {5} & {3} \\\\ {3} & {1 / 5} & {1} & {1 / 3} \\\\ {5} & {1 / 2} & {3} & {1}\\end{array}\\right) \\quad B_{3}=\\left(\\begin{array}{cccc}{1} & {1} & {3} & {3} \\\\ {1} & {1} & {3} & {3} \\\\ {1 / 3} & {1 / 3} & {1} & {1} \\\\ {1 / 7} & {1 / 3} & {1} & {1}\\end{array}\\right)\n$$\n\n\n"},{"metadata":{"id":"55371E8661FD469B88EE88B33FA8C100","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{}},"cell_type":"code","outputs":[],"source":"# 层次分析法函数\nimport numpy as np\ndef AHP(A):\n    lamb,v = np.linalg.eig(A)                      # 调用 np.linalg.eig方法计算矩阵的特征值和特征向量，其中lamb是特征值，v是特征向量\n    lambda_max = max(abs(lamb))                    # 提取最大的特征值\n    loc = np.where(lamb == lambda_max)             # 获取最大特征值的索引\n    weight = abs(v[0:len(A),loc[0][0]])            # 获取最大特征值对应的特征向量\n    RI_list = [0 ,0 ,0.58,0.9,1.12,1.24,1.32,1.41,1.45]   \n    RI = RI_list[len(A)-1]                        # 计算RI\n    CI = (lambda_max - len(A))/(len(A)-1)         # 计算CI\n    CR = CI / RI                                   # 计算CR\n    print('最大特征值 lambda_max=',lambda_max)\n    print('最大特征值对应的特征向量 w=',weight)\n    print('CI=',CI)\n    print('RI=',RI)\n    print('CR=',CR)\n    return weight,CI,RI,CR","execution_count":4},{"metadata":{"id":"4909AF969BA842DBA64349A1BD8A9ACD","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{}},"cell_type":"code","outputs":[{"output_type":"stream","text":"最大特征值 lambda_max= 5.072084408570216\n最大特征值对应的特征向量 w= [0.46582183 0.84086331 0.09509743 0.17329948 0.19204866]\nCI= 0.018021102142554035\nRI= 1.12\nCR= 0.01609026977013753\n","name":"stdout"}],"source":"A = np.array([[1, 1/2, 4,3,3],\n             [2,  1,    7,5,5],\n             [1/4, 1/7,   1,1/2,1/3],\n             [1/3,1/5,2,1,1],\n             [1/3,1/5,3,1,1]])\n# A = np.array([[1, 1/5, 1/3],\n#              [5,  1,    3],\n#              [3, 1/3,   1]])            # 输入判断矩阵\nweight,CI,RI,CR = AHP(A)","execution_count":6},{"metadata":{"id":"60A6F03D5B714D59A6A5B32130BBD720","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{}},"cell_type":"code","outputs":[{"output_type":"stream","text":"最大特征值 lambda_max= 4.788701831199923\n最大特征值对应的特征向量 w= [0.82658145 0.46109858 0.14590859 0.27045896 0.09855884]\nCI= -0.05282454220001931\nRI= 1.12\nCR= -0.04716476982144581\n","name":"stdout"}],"source":"B1 = np.array([[1, 2, 3, 4, 7],\n             [1/3, 1, 3, 2, 5],\n             [1/5, 1/3, 1, 1/2, 1],\n             [1/4, 1/2, 2, 1, 3],\n             [1/7, 1/5, 1/2, 1/3, 1]])     # 输入判断矩阵\nweight,CI,RI,CR = AHP(B1)","execution_count":35},{"metadata":{"id":"95DB3AB087874CA99621B93567F7EA1C","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{}},"cell_type":"code","outputs":[{"output_type":"stream","text":"最大特征值 lambda_max= 4.204930164418752\n最大特征值对应的特征向量 w= [0.08512486 0.8766546  0.17994402 0.43800756]\nCI= 0.06831005480625052\nRI= 0.9\nCR= 0.07590006089583391\n","name":"stdout"}],"source":"B2 = np.array([[1, 1/7, 1/3, 1/5],\n              [7,  1, 5 , 3],\n              [3, 1/5, 1, 1/3],\n              [5, 1/2, 3 , 1]])             # 输入判断矩阵\nweight,CI,RI,CR = AHP(B2)","execution_count":36},{"metadata":{"id":"D73DD91A65EA45098F1E10C3EAFE9A77","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"jupyter":{}},"cell_type":"code","outputs":[{"output_type":"stream","text":"最大特征值 lambda_max= 3.9999999999999996\n最大特征值对应的特征向量 w= [0.67082039 0.67082039 0.2236068  0.2236068 ]\nCI= -1.4802973661668753e-16\nRI= 0.9\nCR= -1.644774851296528e-16\n","name":"stdout"}],"source":"B3 = np.array([[1,1,3,3],\n             [1,1,3,3],\n             [1/3, 1/3, 1, 1],\n              [1/3,1/3,1,1]])     # 输入判断矩阵\nweight,CI,RI,CR = AHP(B3)","execution_count":37},{"metadata":{"id":"98F66DA17FA343968C5A0D7D3428B44B","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"\n![Image Name](https://cdn.kesci.com/upload/image/q37bsjooi.png?imageView2/0/w/960/h/960)\n"},{"metadata":{"id":"84083F98FCF942E8BB772395EA8FFEC1","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## 突出局部差异的客观赋权方法\n\n设$n$个评价对象$m$个指标的观测值分别为$a_{i j}(i=1,2, \\cdots, n ; j=1,2, \\cdots, m)$,记第$j$项指标的样本均值与样本标准差分别为\n$$\n\\mu_{j}=\\frac{1}{n} \\sum_{i=1}^{n} a_{i j}, s_{j}=\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}\\left(a_{i j}-\\mu_{j}\\right)^{2}}\n$$\n\n取第$j$项指标的权重系数为\n$$\nw_{j}=\\frac{s_{j}}{\\sum_{k=1}^{m} s_{k}}(j=1,2, \\cdots, m)\n$$\n\n熵权法的原理和使用案例也在后续章节介绍。"},{"metadata":{"id":"3C4BF92E56A244238E662603F63E9F70","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"## 熵权法"},{"metadata":{"id":"4EC3F1AB84E34AEA8B1E20C648E13F6A","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"在信息论中，熵是对不确定性的一种度量。信息量越大，不确定性就越小，熵也就越小；信息量越小，不确定性越大，熵也越大。\n\n根据熵的特性，可以通过计算熵值来判断一个事件的随机性及无序程度，也可以用熵值来判断某个指标的离散程度，指标的离散程度越大，该指标对综合评价的影响（权重）越大。比如样本数据在某指标下取值都相等，则该指标对总体评价的影响为0，权值为0.\n\n熵权法是一种客观赋权法，因为它仅依赖于数据本身的离散性。\n"},{"metadata":{"id":"1C12D2A409AB4EEF8A4D1182DBC4E2C1","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"\n![Image Name](https://cdn.kesci.com/upload/image/q37dtxb27y.png?imageView2/0/w/320/h/320)\n"},{"metadata":{"id":"B7E79990B95340B095C03B05E7EF8106","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"某医院为了提高自身的护理水平，对拥有的11个科室进行了考核，考核标准包括9项整体护理，并对护理水平较好的科室进行奖励。下表是对各个科室指标考核后的评分结果。\n\n\n![Image Name](https://cdn.kesci.com/upload/image/q37bu55zpt.png?imageView2/0/w/960/h/960)\n\n"},{"metadata":{"id":"926759B5789F44D0ACA96A010441B5CA","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"但是由于各项护理的难易程度不同，因此需要对9项护理进行赋权，以便能够更加合理的对各个科室的护理水平进行评价。根据原始评分表，对数据进行标准化后可以得到下列数据标准化表\n\n\n![Image Name](https://cdn.kesci.com/upload/image/q37bvhlzaq.png?imageView2/0/w/960/h/960)\n\n"},{"metadata":{"id":"57F0425F870A415D8E59DFF724A9B6B7","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"计算第$j$项指标下第$i$个样本值所占比重\n$$\np_{i j}=\\frac{x_{i j}}{\\sum_{i=1}^{n} x_{i j}}, \\quad i=1, \\cdots, n, j=1, \\cdots, m\n$$\n\n计算第$j$个指标的熵值\n$$\ne_{j}=-k \\sum_{i=1}^{n} p_{i j} \\ln \\left(p_{i j}\\right), \\quad j=1, \\cdots, m\n$$\n其中，\n$$\nk=1 / \\ln (n)>0\n$$\n\n\n![Image Name](https://cdn.kesci.com/upload/image/q37c01lxpn.png?imageView2/0/w/960/h/960)\n\n"},{"metadata":{"id":"51CECEB2915F435E8C8C64EEC48BD1E1","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"计算信息熵冗余度，并将其归一化得到权重\n\n$$\nd_{j}=1-e_{j}, \\quad j=1, \\cdots, m\n$$\n\n$$\nw_{j}=\\frac{d_{j}}{\\sum_{j=1}^{m} d_{j}}, \\quad j=1, \\cdots, m\n$$\n\n\n![Image Name](https://cdn.kesci.com/upload/image/q37c2m8er3.png?imageView2/0/w/960/h/960)\n"},{"metadata":{"id":"8BB51846F28F442981FD560BC47610C6","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"计算指标综合评分\n$$\ns_{i}=\\sum_{j=1}^{m} w_{j} x_{i j}, \\quad i=1, \\cdots, n\n$$\n\n\n![Image Name](https://cdn.kesci.com/upload/image/q37c42bx6w.png?imageView2/0/w/960/h/960)\n"},{"metadata":{"id":"3F40D9A010BA4055AAF9C29FC3472718","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"### 总结：熵权法步骤"},{"metadata":{"id":"84EFE7AF4F654270894B7922708B2088","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"1. 对$n$个样本，$m$个指标的数据集\n$$\n\\{x_{ij}|i = 1,2,\\cdots,n, \\quad j = 1,2,\\cdots,m\\}\n$$\n2. 对指标进行归一化处理：异质指标同质化\n3. 计算第$j$项指标下第$i$个样本值所占比重\n$$\np_{i j}=\\frac{x_{i j}}{\\sum_{i=1}^{n} x_{i j}}, \\quad i=1, \\cdots, n, j=1, \\cdots, m\n$$\n4. 计算第$j$个指标的熵值\n$$\ne_{j}=-k \\sum_{i=1}^{n} p_{i j} \\ln \\left(p_{i j}\\right), \\quad j=1, \\cdots, m\n$$\n其中，\n$$\nk=1 / \\ln (n)>0\n$$\n4. 计算信息熵冗余度，并将其归一化得到权重\n$$\nd_{j}=1-e_{j}, \\quad j=1, \\cdots, m\n$$\n$$\nw_{j}=\\frac{d_{j}}{\\sum_{j=1}^{m} d_{j}}, \\quad j=1, \\cdots, m\n$$\n6. 计算指标综合评分\n$$\ns_{i}=\\sum_{j=1}^{m} w_{j} x_{i j}, \\quad i=1, \\cdots, n\n$$\n这里的$x_{ij}$是标准化以后的数据。"},{"metadata":{"id":"5C4E0688BF014CE88ED6FEC0A9F48CC5","tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"# 评价问题总结"},{"metadata":{"id":"C4D1B3BAA2B04FA699AFA18990E81489","tags":[],"slideshow":{"slide_type":"slide"},"collapsed":false,"scrolled":false,"mdEditEnable":false,"jupyter":{}},"cell_type":"markdown","source":"评价问题的流程：\n1. 筛选指标\n2. 指标一致化和无量纲化\n3. 确定权重\n4. 使用合适的综合评价方法，加权综合求评分,得到结果\n\n\n方法的选择：\n- 优先选择客观方法，但也具有其局限性\n- 如果选用了主观方法（AHP）,一定不要忘记一致性检验和敏感性分析"},{"metadata":{"id":"284E1FFC98E54E94805BD3D928456DA0","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"mdEditEnable":false},"cell_type":"markdown","source":"# 思考作业\n\n学完本节课的知识，你会如何解决2018年的HiMCM A题？"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}